{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Tuples\n",
    "2. Dictionary\n",
    "3. Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes\n",
    "Some variants in class :\n",
    "1. Slots - Saves memory\n",
    "2. DataClasses- Reduce coding\n",
    "3. Named Tuples - Immutability behaviour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slots\n",
    "\n",
    "For data structure use `__slots__` to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('GOOG', 440.1, 100)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Stock:\n",
    "    __slots__ = ('name','shares','price') # used for performance optimization\n",
    "    def __init__(self,name,shares,price):\n",
    "        self.name = name\n",
    "        self.shares = shares\n",
    "        self.price = price\n",
    "\n",
    "s = Stock('GOOG',100,440.10)\n",
    "s.name,s.price,s.shares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataclasses\n",
    "`dataclass` is a decorator in python and it automatically generates special methods like `__init__()`,`__repr__()` and `__eq__()` for user defined classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='HE', age=10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Person:\n",
    "    name : str\n",
    "    age : int\n",
    "\n",
    "p = Person(name=\"HE\",age=10)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Tuples\n",
    "There are two types of named tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### From `typing` class\n",
    "It provides *type hints*, you can access the immutable data structure with name fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='HE', age=10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from typing import NamedTuple\n",
    "\n",
    "class Person(NamedTuple):\n",
    "    name : str\n",
    "    age : int\n",
    "\n",
    "p = Person(name=\"HE\",age=10)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From `collections`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='HE', age=10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Person = namedtuple('Person',['name','age']) # class\n",
    "s = Person(\"HE\",10)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Objectives:*\n",
    "\n",
    "- Figure out the most memory-efficient way to store a lot of data.\n",
    "- Learn about different ways of representing records including tuples,\n",
    "dictionaries, classes, and named tuples.\n",
    "\n",
    "In this exercise, we look at different choices for representing data\n",
    "structures with an eye towards memory use and efficiency.  A lot of\n",
    "people use Python to perform various kinds of data analysis so knowing\n",
    "about different options and their tradeoffs is useful information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### (a) Stuck on the bus\n",
    "\n",
    "The file `Data/ctabus.csv` is a CSV file containing\n",
    "daily ridership data for the Chicago Transit Authority (CTA) bus\n",
    "system from January 1, 2001 to August 31, 2013.  It contains\n",
    "approximately 577000 rows of data.  Use Python to view a few lines\n",
    "of data to see what it looks like:\n",
    "\n",
    "```python\n",
    ">>> f = open('Data/ctabus.csv')\n",
    ">>> next(f)\n",
    "'route,date,daytype,rides\\n'\n",
    ">>> next(f)\n",
    "'3,01/01/2001,U,7354\\n'\n",
    ">>> next(f)\n",
    "'4,01/01/2001,U,9288\\n'\n",
    ">>>\n",
    "```\n",
    "\n",
    "There are 4 columns of data.\n",
    "\n",
    "- route: Column 0.  The bus route name.\n",
    "- date: Column 1.  A date string of the form MM/DD/YYYY.\n",
    "- daytype: Column 2. A day type code (U=Sunday/Holiday, A=Saturday, W=Weekday)\n",
    "- rides: Column 3. Total number of riders (integer)\n",
    "\n",
    "The `rides` column records the total number of people who boarded a\n",
    "bus on that route on a given day. Thus, from the example, 7354 people\n",
    "rode the number 3 bus on January 1, 2001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'route': '3', 'date': '01/01/2001', 'daytype': 'U', 'rides': '7354\\n'}\n",
      "{'route': '4', 'date': '01/01/2001', 'daytype': 'U', 'rides': '9288\\n'}\n",
      "{'route': '6', 'date': '01/01/2001', 'daytype': 'U', 'rides': '6048\\n'}\n",
      "{'route': '8', 'date': '01/01/2001', 'daytype': 'U', 'rides': '6309\\n'}\n",
      "{'route': '9', 'date': '01/01/2001', 'daytype': 'U', 'rides': '11207\\n'}\n"
     ]
    }
   ],
   "source": [
    "def collect_data(filename):\n",
    "    record = []\n",
    "    with open(filename,mode='r') as file:\n",
    "        for line in file:\n",
    "            route,date,daytype,rides = line.split(',')\n",
    "            record.append(\n",
    "                {\n",
    "                    'route':route,\n",
    "                    'date' : date,\n",
    "                    'daytype' : daytype,\n",
    "                    'rides':rides\n",
    "                }\n",
    "            )\n",
    "        \n",
    "    return record[1:]\n",
    "\n",
    "file_path = \"learning-python-mastery/Data/ctabus.csv\"\n",
    "data = collect_data(file_path)\n",
    "\n",
    "limit = 5\n",
    "\n",
    "for d in data[:limit]:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### (b) Basic memory use of text\n",
    "\n",
    "Let's get a baseline of the memory required to work with this\n",
    "datafile.  First, restart Python and try a very simple experiment of\n",
    "simply grabbing the file and storing its data in a single string:\n",
    "\n",
    "```python\n",
    ">>> # --- RESTART \n",
    ">>> import tracemalloc\n",
    ">>> f = open('Data/ctabus.csv')\n",
    ">>> tracemalloc.start()\n",
    ">>> data = f.read()\n",
    ">>> len(data)\n",
    "12361039\n",
    ">>> current, peak = tracemalloc.get_traced_memory()\n",
    ">>> current\n",
    "12369664\n",
    ">>> peak\n",
    "24730766\n",
    ">>> \n",
    "```\n",
    "\n",
    "Your results might vary somewhat, but you should see current\n",
    "memory use in the range of 12MB with a peak of 24MB.\n",
    "\n",
    "What happens if you read the entire file into a list of strings\n",
    "instead?  Restart Python and try this:\n",
    "\n",
    "```python\n",
    ">>> # --- RESTART\n",
    ">>> import tracemalloc\n",
    ">>> f = open('Data/ctabus.csv')\n",
    ">>> tracemalloc.start()\n",
    ">>> lines = f.readlines()\n",
    ">>> len(lines)\n",
    "577564\n",
    ">>> current, peak = tracemalloc.get_traced_memory()\n",
    ">>> current\n",
    "45828030\n",
    ">>> peak\n",
    "45867371\n",
    ">>> \n",
    "```\n",
    "\n",
    "You should see the memory use go up significantly into the range of 40-50MB.\n",
    "Point to ponder: what might be the source of that extra overhead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single String :  (12361616, 38816419)\n",
      "List : (40740991, 40749556)\n"
     ]
    }
   ],
   "source": [
    "from tracemalloc import start,get_traced_memory\n",
    "\n",
    "def single_string_mem(file):\n",
    "    f = open(file)\n",
    "    start()\n",
    "    l = f.read()\n",
    "    return get_traced_memory()\n",
    "\n",
    "def list_mem(file):\n",
    "    f = open(file)\n",
    "    start()\n",
    "    l = f.readlines()\n",
    "    return get_traced_memory()\n",
    "\n",
    "file_path = \"learning-python-mastery/Data/ctabus.csv\"\n",
    "print(\"Single String : \",single_string_mem(file_path))\n",
    "print(\"List :\",list_mem(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Point to ponder**\n",
    "\n",
    "*What might be the source of that extra overhead?*\n",
    "\n",
    "**Solution**\n",
    "\n",
    "1. When using `read()` function, it stores all the data in a single string which stores in contiguous memory location\n",
    "2. When using `readlines()` function, it produces a list of string elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) A List of Tuples\n",
    "\n",
    "In practice, you might read the data into a list and convert each line\n",
    "into some other data structure.  Here is a program `readrides.py` that\n",
    "reads the entire file into a list of tuples using the `csv` module:\n",
    "\n",
    "```python\n",
    "# readrides.py\n",
    "\n",
    "import csv\n",
    "\n",
    "def read_rides_as_tuples(filename):\n",
    "    '''\n",
    "    Read the bus ride data as a list of tuples\n",
    "    '''\n",
    "    records = []\n",
    "    with open(filename) as f:\n",
    "        rows = csv.reader(f)\n",
    "        headings = next(rows)     # Skip headers\n",
    "        for row in rows:\n",
    "            route = row[0]\n",
    "            date = row[1]\n",
    "            daytype = row[2]\n",
    "            rides = int(row[3])\n",
    "            record = (route, date, daytype, rides)\n",
    "            records.append(record)\n",
    "    return records\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import tracemalloc\n",
    "    tracemalloc.start()\n",
    "    rows = read_rides_as_tuples('Data/ctabus.csv')\n",
    "    print('Memory Use: Current %d, Peak %d' % tracemalloc.get_traced_memory())\n",
    "```\n",
    "\n",
    "Run this program using `python3 -i readrides.py` and look at the\n",
    "resulting contents of `rows`. You should get a list of tuples like\n",
    "this:\n",
    "\n",
    "```python\n",
    ">>> len(rows)\n",
    "577563\n",
    ">>> rows[0]\n",
    "('3', '01/01/2001', 'U', 7354)\n",
    ">>> rows[1]\n",
    "('4', '01/01/2001', 'U', 9288)\n",
    "```\n",
    "\n",
    "Look at the resulting memory use. It should be substantially higher\n",
    "than in part (b).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current : 191229264 Peak :386406418\n"
     ]
    }
   ],
   "source": [
    "import tracemalloc\n",
    "file_path = \"learning-python-mastery/Data/ctabus.csv\"\n",
    "tracemalloc.start()\n",
    "data = collect_data(file_path)\n",
    "curr,peak = tracemalloc.get_traced_memory()\n",
    "print(f\"Current : {curr} Peak :{peak}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Memory Use of Other Data Structures\n",
    "\n",
    "Python has many different choices for representing data structures.\n",
    "For example:\n",
    "\n",
    "```python\n",
    "# A tuple\n",
    "row = (route, date, daytype, rides)\n",
    "\n",
    "# A dictionary\n",
    "row = {\n",
    "    'route': route,\n",
    "    'date': date,\n",
    "    'daytype': daytype,\n",
    "    'rides': rides,\n",
    "}\n",
    "\n",
    "# A class\n",
    "class Row:\n",
    "    def __init__(self, route, date, daytype, rides):\n",
    "        self.route = route\n",
    "        self.date = date\n",
    "        self.daytype = daytype\n",
    "        self.rides = rides\n",
    "\n",
    "# A named tuple\n",
    "from collections import namedtuple\n",
    "Row = namedtuple('Row', ['route', 'date', 'daytype', 'rides'])\n",
    "\n",
    "# A class with __slots__\n",
    "class Row:\n",
    "    __slots__ = ['route', 'date', 'daytype', 'rides']\n",
    "    def __init__(self, route, date, daytype, rides):\n",
    "        self.route = route\n",
    "        self.date = date\n",
    "        self.daytype = daytype\n",
    "        self.rides = rides\n",
    "```\n",
    "Your task is as follows:  Create different versions of the `read_rides()` function\n",
    "that use each of these data structures to represent a single row of data.\n",
    "Then, find out the resulting memory use of each option.   Find out which\n",
    "approach offers the most efficient storage if you were working with a lot \n",
    "of data all at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Structure | Row Count | Current Memory (MB) | Peak Memory (MB)\n",
      "---------------|-----------|----------------------|------------------\n",
      "Tuple          |    577564 |               120.02 |           120.05\n",
      "Dictionary     |    577564 |               181.14 |           181.17\n",
      "Class          |    577564 |               132.68 |           132.72\n",
      "Named Tuple    |    577564 |               123.87 |           123.90\n",
      "Slotted Class  |    577564 |               115.06 |           115.09\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import tracemalloc\n",
    "from collections import namedtuple\n",
    "\n",
    "def read_rides_tuple(filename):\n",
    "    with open(filename) as f:\n",
    "        rows = []\n",
    "        for route, date, daytype, rides in csv.reader(f):\n",
    "            rows.append((route, date, daytype, rides))\n",
    "    return rows\n",
    "\n",
    "def read_rides_dict(filename):\n",
    "    with open(filename) as f:\n",
    "        return [{'route': route, 'date': date, 'daytype': daytype, 'rides': rides}\n",
    "                for route, date, daytype, rides in csv.reader(f)]\n",
    "\n",
    "class Row:\n",
    "    def __init__(self, route, date, daytype, rides):\n",
    "        self.route = route\n",
    "        self.date = date\n",
    "        self.daytype = daytype\n",
    "        self.rides = rides\n",
    "\n",
    "def read_rides_class(filename):\n",
    "    with open(filename) as f:\n",
    "        return [Row(route, date, daytype, rides)\n",
    "                for route, date, daytype, rides in csv.reader(f)]\n",
    "\n",
    "NamedTupleRow = namedtuple('NamedTupleRow', ['route', 'date', 'daytype', 'rides'])\n",
    "\n",
    "def read_rides_namedtuple(filename):\n",
    "    with open(filename) as f:\n",
    "        return [NamedTupleRow(route, date, daytype, rides)\n",
    "                for route, date, daytype, rides in csv.reader(f)]\n",
    "\n",
    "class SlottedRow:\n",
    "    __slots__ = ['route', 'date', 'daytype', 'rides']\n",
    "    def __init__(self, route, date, daytype, rides):\n",
    "        self.route = route\n",
    "        self.date = date\n",
    "        self.daytype = daytype\n",
    "        self.rides = rides\n",
    "\n",
    "def read_rides_slotted(filename):\n",
    "    with open(filename) as f:\n",
    "        return [SlottedRow(route, date, daytype, rides)\n",
    "                for route, date, daytype, rides in csv.reader(f)]\n",
    "\n",
    "def measure_memory(func, filename):\n",
    "    tracemalloc.start()\n",
    "    result = func(filename)\n",
    "    current, peak = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "    return len(result), current, peak\n",
    "\n",
    "filename = 'learning-python-mastery/Data/ctabus.csv'\n",
    "functions = [\n",
    "    ('Tuple', read_rides_tuple),\n",
    "    ('Dictionary', read_rides_dict),\n",
    "    ('Class', read_rides_class),\n",
    "    ('Named Tuple', read_rides_namedtuple),\n",
    "    ('Slotted Class', read_rides_slotted)\n",
    "]\n",
    "\n",
    "print(\"Data Structure | Row Count | Current Memory (MB) | Peak Memory (MB)\")\n",
    "print(\"---------------|-----------|----------------------|------------------\")\n",
    "\n",
    "for name, func in functions:\n",
    "    count, current, peak = measure_memory(func, filename)\n",
    "    print(f\"{name:<14} | {count:9d} | {current/1024/1024:20.2f} | {peak/1024/1024:16.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranking of Data Structure from high to low:\n",
    "1. Dictionary\n",
    "2. Class\n",
    "3. Named Tuple\n",
    "4. Dictionary\n",
    "5. Slotted Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Containers and Collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. List Comprehension\n",
    "\n",
    "`[expression for item in sequence if condition]`\n",
    "\n",
    "2. Set Comprehension\n",
    "\n",
    "`{expression for item in sequence if condition}`\n",
    "\n",
    "3. Dict Comprehension\n",
    "\n",
    "`{key:value for item in sequence if condition}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Collection` module\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Dict\n",
    "It provides a default value for a non existent key, which prevents `KeyError`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {'x': [1, 2, 3], 'y': [4, 5, 6]})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "d = defaultdict(list)\n",
    "d['x'] = [1,2,3]\n",
    "d['y'] = [4,5,6]\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counter\n",
    "* It is a subclass of `dict` designed to count hashable objects\n",
    "* It counts the number of times each element appears in an iterable and stores the counts as dictionary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({'B': 40, 'A': 20}), [('B', 40), ('A', 20)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter()\n",
    "counter['A'] += 20\n",
    "counter['B'] += 40\n",
    "counter,counter.most_common(2) # ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deque\n",
    "* A double ended queue that allows you to add and remove elements from both ends effeciently.\n",
    "* It provides fast appends and pops from both the left and right sides\n",
    "* Useful for *keeping a history of last **N** things*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([4, 3, 1, 2])\n",
      "2\n",
      "4\n",
      "deque([3, 1])\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "q = deque()\n",
    "q.append(1)\n",
    "q.append(2)\n",
    "q.appendleft(3)\n",
    "q.appendleft(4)\n",
    "print(q)\n",
    "print(q.pop())\n",
    "print(q.popleft())\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Objectives:*\n",
    "\n",
    "- Work with various containers\n",
    "- List/Set/Dict Comprehensions\n",
    "- Collections module\n",
    "- Data analysis challenge\n",
    "\n",
    "Most Python programmers are generally familiar with lists, dictionaries,\n",
    "tuples, and other basic datatypes. In this exercise, we'll put that\n",
    "knowledge to work to solve various data analysis problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Preliminaries\n",
    "\n",
    "To get started, let's review some basics with a slightly simpler dataset--\n",
    "a portfolio of stock holdings. Create a file `readport.py` and put this\n",
    "code in it:\n",
    "\n",
    "```python\n",
    "# readport.py\n",
    "\n",
    "import csv\n",
    "\n",
    "# A function that reads a file into a list of dicts\n",
    "def read_portfolio(filename):\n",
    "    portfolio = []\n",
    "    with open(filename) as f:\n",
    "        rows = csv.reader(f)\n",
    "        headers = next(rows)\n",
    "        for row in rows:\n",
    "            record = {\n",
    "                'name' : row[0],\n",
    "                'shares' : int(row[1]),\n",
    "                'price' : float(row[2])\n",
    "            }\n",
    "            portfolio.append(record)\n",
    "    return portfolio\n",
    "```\n",
    "\n",
    "This file reads some simple stock market data in the file `Data/portfolio.csv`.  Use\n",
    "the function to read the file and look at the results:\n",
    "\n",
    "```python\n",
    ">>> portfolio = read_portfolio('Data/portfolio.csv')\n",
    ">>> from pprint import pprint\n",
    ">>> pprint(portfolio)\n",
    "[{'name': 'AA', 'price': 32.2, 'shares': 100},\n",
    " {'name': 'IBM', 'price': 91.1, 'shares': 50},\n",
    " {'name': 'CAT', 'price': 83.44, 'shares': 150},\n",
    " {'name': 'MSFT', 'price': 51.23, 'shares': 200},\n",
    " {'name': 'GE', 'price': 40.37, 'shares': 95},\n",
    " {'name': 'MSFT', 'price': 65.1, 'shares': 50},\n",
    " {'name': 'IBM', 'price': 70.44, 'shares': 100}]\n",
    ">>>\n",
    "```\n",
    "\n",
    "In this data, each row consists of a stock name, a number of held\n",
    "shares, and a purchase price.   There are multiple entries for\n",
    "certain stock names such as MSFT and IBM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Comprehensions\n",
    "\n",
    "List, set, and dictionary comprehensions can be a useful tool for manipulating\n",
    "data.  For example, try these operations:\n",
    "\n",
    "```python\n",
    ">>> # Find all holdings more than 100 shares\n",
    ">>> [s for s in portfolio if s['shares'] > 100]\n",
    "[{'name': 'CAT', 'shares': 150, 'price': 83.44}, \n",
    " {'name': 'MSFT', 'shares': 200, 'price': 51.23}]\n",
    "\n",
    ">>> # Compute total cost (shares * price)\n",
    ">>> sum([s['shares']*s['price'] for s in portfolio])\n",
    "44671.15\n",
    ">>>\n",
    "\n",
    ">>> # Find all unique stock names (set)\n",
    ">>> { s['name'] for s in portfolio }\n",
    "{'MSFT', 'IBM', 'AA', 'GE', 'CAT'}\n",
    ">>>\n",
    "\n",
    ">>> # Count the total shares of each of stock\n",
    ">>> totals = { s['name']: 0 for s in portfolio }\n",
    ">>> for s in portfolio:\n",
    "        totals[s['name']] += s['shares']\n",
    "\n",
    ">>> totals\n",
    "{'AA': 100, 'IBM': 150, 'CAT': 150, 'MSFT': 250, 'GE': 95}\n",
    ">>> \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Collections\n",
    "\n",
    "The `collections` module has a variety of classes for more specialized data\n",
    "manipulation.  For example, the last example could be solved with a `Counter` like this:\n",
    "\n",
    "```python\n",
    ">>> from collections import Counter\n",
    ">>> totals = Counter()\n",
    ">>> for s in portfolio:\n",
    "        totals[s['name']] += s['shares']\n",
    "\n",
    ">>> totals\n",
    "Counter({'MSFT': 250, 'IBM': 150, 'CAT': 150, 'AA': 100, 'GE': 95})\n",
    ">>>\n",
    "```\n",
    "\n",
    "Counters are interesting in that they support other kinds of operations such as ranking\n",
    "and mathematics.  For example:\n",
    "\n",
    "```python\n",
    ">>> # Get the two most common holdings\n",
    ">>> totals.most_common(2)\n",
    "[('MSFT', 250), ('IBM', 150)]\n",
    ">>>\n",
    "\n",
    ">>> # Adding counters together\n",
    ">>> more = Counter()\n",
    ">>> more['IBM'] = 75\n",
    ">>> more['AA'] = 200\n",
    ">>> more['ACME'] = 30\n",
    ">>> more\n",
    "Counter({'AA': 200, 'IBM': 75, 'ACME': 30})\n",
    ">>> totals\n",
    "Counter({'MSFT': 250, 'IBM': 150, 'CAT': 150, 'AA': 100, 'GE': 95})\n",
    ">>> totals + more\n",
    "Counter({'AA': 300, 'MSFT': 250, 'IBM': 225, 'CAT': 150, 'GE': 95, 'ACME': 30})\n",
    ">>> \n",
    "```\n",
    "\n",
    "The `defaultdict` object can be used to group data.  For example, suppose\n",
    "you want to make it easy to find all matching entries for a given name such as\n",
    "IBM.  Try this:\n",
    "\n",
    "```python\n",
    ">>> from collections import defaultdict\n",
    ">>> byname = defaultdict(list)\n",
    ">>> for s in portfolio:\n",
    "        byname[s['name']].append(s)\n",
    "\n",
    ">>> byname['IBM']\n",
    "[{'name': 'IBM', 'shares': 50, 'price': 91.1}, {'name': 'IBM', 'shares': 100, 'price': 70.44}]\n",
    ">>> byname['AA']\n",
    "[{'name': 'AA', 'shares': 100, 'price': 32.2}]\n",
    ">>>\n",
    "```\n",
    "\n",
    "The key feature that makes this work is that a defaultdict\n",
    "automatically initializes elements for you--allowing an insertion of a\n",
    "new element and an `append()` operation to be combined together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Data Analysis Challenge\n",
    "\n",
    "In the last exercise you just wrote some code to read CSV-data related\n",
    "to the Chicago Transit Authority.  For example, you can grab the data\n",
    "as dictionaries like this:\n",
    "\n",
    "```python\n",
    ">>> import readrides\n",
    ">>> rows = readrides.read_rides_as_dicts('Data/ctabus.csv')\n",
    ">>>\n",
    "```\n",
    "\n",
    "It would be a shame to do all of that work and then do nothing with\n",
    "the data.\n",
    "\n",
    "In this exercise, your task is this: write a program to answer the\n",
    "following three questions:\n",
    "\n",
    "1. How many bus routes exist in Chicago?\n",
    "\n",
    "2. How many people rode the number 22 bus on February 2, 2011?  What about any route on any date of your choosing?\n",
    "\n",
    "3. What is the total number of rides taken on each bus route?\n",
    "\n",
    "4. What five bus routes had the greatest ten-year increase in ridership from 2001 to 2011?\n",
    "\n",
    "You are free to use any technique whatsoever to answer the above\n",
    "questions as long as it's part of the Python standard library (i.e.,\n",
    "built-in datatypes, standard library modules, etc.). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'route': '3', 'date': '01/01/2001', 'daytype': 'U', 'rides': 7354},\n",
       " {'route': '4', 'date': '01/01/2001', 'daytype': 'U', 'rides': 9288},\n",
       " {'route': '6', 'date': '01/01/2001', 'daytype': 'U', 'rides': 6048},\n",
       " {'route': '8', 'date': '01/01/2001', 'daytype': 'U', 'rides': 6309},\n",
       " {'route': '9', 'date': '01/01/2001', 'daytype': 'U', 'rides': 11207}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def read_rides_as_dicts(filename):\n",
    "    '''\n",
    "    Read the bus ride data as a list of dicts\n",
    "    '''\n",
    "    records = []\n",
    "    with open(filename) as f:\n",
    "        rows = csv.reader(f)\n",
    "        headings = next(rows)     # Skip headers\n",
    "        for row in rows:\n",
    "            route = row[0]\n",
    "            date = row[1]\n",
    "            daytype = row[2]\n",
    "            rides = int(row[3])\n",
    "            record = {\n",
    "                'route': route, \n",
    "                'date': date, \n",
    "                'daytype': daytype, \n",
    "                'rides' : rides\n",
    "                }\n",
    "            records.append(record)\n",
    "    return records\n",
    "    \n",
    "rows = read_rides_as_dicts(\"E:/jai/docs/code/python/tutorial/learning-python-mastery/Data/ctabus.csv\")\n",
    "rows[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182 routes\n"
     ]
    }
   ],
   "source": [
    "# How many routes are in Chichago?\n",
    "routes = set()\n",
    "for row in rows:\n",
    "    routes.add(row['route'])\n",
    "print(len(routes), 'routes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rides : 5055\n"
     ]
    }
   ],
   "source": [
    "# How many people rode the number 22 bus on February 2, 2011?  \n",
    "# What about any route on any date of your choosing?\n",
    "for i in rows:\n",
    "    if i['route'] == '22' and i['date'] == '02/02/2011':\n",
    "        print(\"Total rides :\",i['rides'])\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   79  133796763\n",
      "    9  117923787\n",
      "   49   95915008\n",
      "    4   95309438\n",
      "   66   93053461\n",
      "  151   89524268\n",
      "   22   89380790\n",
      "    3   89211071\n",
      "   77   88484043\n",
      "   53   86884085\n",
      "   20   86679321\n",
      "   63   86609336\n",
      "    8   84362672\n",
      "   82   74427970\n",
      "   36   68780696\n",
      "   72   66184985\n",
      "   87   65522213\n",
      "   29   65048709\n",
      "   81   59612673\n",
      "   67   57880229\n",
      "   62   53418231\n",
      "   60   52860939\n",
      "   55   52724358\n",
      "    6   52654473\n",
      "  147   52379267\n",
      "   56   52280435\n",
      "   74   52111931\n",
      "   80   51543475\n",
      "   12   51168351\n",
      "   52   49851059\n",
      "   85   49776812\n",
      "   54   47976060\n",
      "   76   47452382\n",
      "   47   44111483\n",
      "   70   42640960\n",
      "  146   42089695\n",
      "   71   41754367\n",
      "   14   41094492\n",
      "  152   40352452\n",
      "   94   39817262\n",
      "   78   35433146\n",
      "   21   35216129\n",
      "   50   34166525\n",
      "  126   33268789\n",
      "   28   33033639\n",
      "   75   32597029\n",
      "   91   32296856\n",
      "  53A   31898628\n",
      "   92   29983360\n",
      "  155   29450367\n",
      "  156   28882051\n",
      "   65   28161390\n",
      "   15   26149468\n",
      "   34   25709239\n",
      "  145   25428790\n",
      "  X49   24110395\n",
      "  119   24028072\n",
      "  111   23663300\n",
      "   35   22291648\n",
      "   44   22004694\n",
      "   73   21639876\n",
      "  95E   21582109\n",
      "  52A   21178110\n",
      "  49B   20997838\n",
      "    7   20243195\n",
      "   90   20101625\n",
      "  95W   19915671\n",
      "  54B   18198815\n",
      "   84   16305261\n",
      "   11   16060502\n",
      "   8A   15512245\n",
      "   97   14790421\n",
      "  103   13649517\n",
      "   59   13638703\n",
      "   30   13245844\n",
      "  112   12701781\n",
      "    1   12380996\n",
      "   24   12324872\n",
      "  157   12044995\n",
      "   57   11526282\n",
      "   51   11434393\n",
      "   93   11126570\n",
      "  135   10639369\n",
      "   X9    9727671\n",
      "   18    8788532\n",
      "  108    7958095\n",
      "  106    7660770\n",
      "  125    7472645\n",
      "  63W    7344219\n",
      "   86    7186914\n",
      "    2    7079897\n",
      "  X80    7076090\n",
      "  X28    7073855\n",
      "  136    6726484\n",
      "  81W    6662813\n",
      "   26    6655877\n",
      "  134    6577698\n",
      "   39    6410389\n",
      "  201    6087210\n",
      "   88    6057455\n",
      "   43    5996263\n",
      "   68    5630989\n",
      "  121    4986698\n",
      "  X54    4942098\n",
      "  148    4920748\n",
      "  X55    4848920\n",
      "  124    4770015\n",
      "  171    4744053\n",
      "  62H    4668296\n",
      "   27    4588654\n",
      "  172    4508251\n",
      "  120    4389068\n",
      "   37    3965341\n",
      "  54A    3673818\n",
      "   48    3669229\n",
      " 1001    3447912\n",
      "   96    3343405\n",
      "  85A    3275028\n",
      "  100    3146418\n",
      "  J14    3073437\n",
      "  143    3047504\n",
      "  129    2937283\n",
      "  205    2721818\n",
      "  55N    2622561\n",
      "  144    2581625\n",
      "   10    2486917\n",
      "   X4    2439238\n",
      "  56A    2410058\n",
      "  123    2241706\n",
      "   X3    2225982\n",
      "  206    2190873\n",
      "  122    2075144\n",
      "   33    2011513\n",
      "  X20    1980920\n",
      "  49A    1882331\n",
      "  127    1684356\n",
      "   17    1535165\n",
      "   38    1500952\n",
      "  192    1387081\n",
      "  90N    1360211\n",
      "   69    1308483\n",
      "  169    1282996\n",
      "    5    1224396\n",
      "  170    1001109\n",
      "  R95     972858\n",
      "  203     968082\n",
      "  204     916940\n",
      "  130     814952\n",
      "  X98     794267\n",
      "  115     773755\n",
      " 53AL     664698\n",
      "   25     632161\n",
      "  R63     629465\n",
      "  154     617888\n",
      "   64     599089\n",
      "   19     566505\n",
      "  132     522313\n",
      "  X21     496415\n",
      "  173     443496\n",
      "  55A     417388\n",
      "  R79     345494\n",
      "  174     302560\n",
      "  R22     279556\n",
      "  202     276827\n",
      "  R87     269043\n",
      "  200     234800\n",
      "  128     176670\n",
      "  168     164912\n",
      "  R69     158023\n",
      "  165     140129\n",
      " 1002     108109\n",
      " 69BR      85938\n",
      "  R55      69200\n",
      "  X99      54099\n",
      " N201      44750\n",
      "   40      38447\n",
      "  137      25617\n",
      " 290S       7308\n",
      "  290       4440\n",
      "   95       2313\n",
      "  R39        398\n"
     ]
    }
   ],
   "source": [
    "# What is the total number of rides taken on each bus route?\n",
    "from collections import Counter\n",
    "\n",
    "rides_per_route = Counter()\n",
    "\n",
    "for row in rows:\n",
    "    rides_per_route[row['route']] += row['rides']\n",
    "\n",
    "for route, count in rides_per_route.most_common():\n",
    "    print('%5s %10d' % (route, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 2732209\n",
      "147 2107910\n",
      "66 1612958\n",
      "12 1612067\n",
      "14 1351308\n"
     ]
    }
   ],
   "source": [
    "# What five bus routes had the greatest ten-year increase\n",
    "# in ridership from 2001 to 2011?\n",
    "from collections import defaultdict\n",
    "\n",
    "rides_by_year = defaultdict(Counter)\n",
    "for row in rows:\n",
    "    year = row['date'].split('/')[2]\n",
    "    rides_by_year[year][row['route']] += row['rides']\n",
    "\n",
    "diffs = rides_by_year['2011'] - rides_by_year['2001']\n",
    "for route, diff in diffs.most_common(5):\n",
    "    print(route, diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration and Iterables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. For loop\n",
    "2. Iterating on tuples\n",
    "```python\n",
    "for name,share,price in portfolio:\n",
    "    ...\n",
    "```\n",
    "3. Looping varying records:\n",
    "```python\n",
    "price = [\n",
    "    ['GOOG',10,20,30],\n",
    "    ['IBM',10,20],\n",
    "    ['CAT',10,20,30,40]\n",
    "]\n",
    "for name,*values in price:\n",
    "    print(name,values)\n",
    "```\n",
    "4. `zip()` function\n",
    "```python\n",
    "# making dict\n",
    "rec = dict(zip(val1,val2))\n",
    "```\n",
    "5. Keeping a running count - `enumerate()`\n",
    "```python\n",
    "for n,name in enumerate(names):\n",
    "    ...\n",
    "```\n",
    "6. Iterating on integers\n",
    "```python\n",
    "for i in range(start,end,step):\n",
    "    ...\n",
    "```\n",
    "7. Sequence reduction\n",
    "```python\n",
    "sum(s),min(s),max(s),any(s),all(s)\n",
    "```\n",
    "8. Unpacking Iterables - better than using `+`\n",
    "```python\n",
    "a = (1,2,3)\n",
    "b = [4,5]\n",
    "c = [*a,*b] # c = [1,2,3,4,5]\n",
    "d = (*a,*b) # d = (1,2,3,4,5)\n",
    "```\n",
    "9. Unpacking dictionaries\n",
    "```python\n",
    "a = {'name':'GOOG','shares':100,'price':490.1}\n",
    "b = {'date':'6/10/2001','time':'9:45am'}\n",
    "c = {**a,**b} # combining into single dict\n",
    "```\n",
    "10. Argument passing\n",
    "```py\n",
    "a = (1,2,3)\n",
    "b = (4,5)\n",
    "c = {'x':1,'y':2}\n",
    "func(*a,*b) # func(1,2,3,4,5)\n",
    "func(**c) # func(x=1,y=2)\n",
    "func(0,*a,*b,6,variable=37,**c) # order\n",
    "```\n",
    "11. Generator expression - alt to list comprehension, it can be only used once\n",
    "```python\n",
    "nums = [1,2,3,4]\n",
    "sqs = (x*x for x in nums)\n",
    "for n in sqs:\n",
    "    print(n,end='/t')\n",
    "```\n",
    "* It acts as a filter/transform on an iterable\n",
    "12. Generator functions\n",
    "```python\n",
    "def squares(nums):\n",
    "    for x in nums:\n",
    "        yield x*x\n",
    "\n",
    "for n in squares([1,2,3,4]):\n",
    "    ...\n",
    "```\n",
    "\n",
    "To know more about generators, see this [video](https://youtu.be/bD05uGo_sVI?si=p_lMsmWB2p0vu42o)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Objectives:*\n",
    "\n",
    "- Iterate like a pro\n",
    "\n",
    "*Files Modified:* None.\n",
    "\n",
    "Iteration is an essential Python skill.  In this exercise, we look at\n",
    "a number of common iteration idioms.\n",
    "\n",
    "Start the exercise by grabbing some rows of data from a CSV file.\n",
    "\n",
    "```python\n",
    ">>> import csv\n",
    ">>> f = open('Data/portfolio.csv')\n",
    ">>> f_csv = csv.reader(f)\n",
    ">>> headers = next(f_csv)\n",
    ">>> headers\n",
    "['name', 'shares', 'price']\n",
    ">>> rows = list(f_csv)\n",
    ">>> from pprint import pprint\n",
    ">>> pprint(rows)\n",
    "[['AA', '100', '32.20'],\n",
    " ['IBM', '50', '91.10'],\n",
    " ['CAT', '150', '83.44'],\n",
    " ['MSFT', '200', '51.23'],\n",
    " ['GE', '95', '40.37'],\n",
    " ['MSFT', '50', '65.10'],\n",
    " ['IBM', '100', '70.44']]\n",
    ">>>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Basic Iteration and Unpacking\n",
    "\n",
    "The `for` statement iterates over any sequence of data. For example:\n",
    "\n",
    "```python\n",
    ">>> for row in rows:\n",
    "        print(row)\n",
    "\n",
    "['AA', '100', '32.20']\n",
    "['IBM', '50', '91.10']\n",
    "['CAT', '150', '83.44']\n",
    "['MSFT', '200', '51.23']\n",
    "['GE', '95', '40.37']\n",
    "['MSFT', '50', '65.10']\n",
    "['IBM', '100', '70.44']\n",
    ">>>\n",
    "```\n",
    "\n",
    "Unpack the values into separate variables if you need to:\n",
    "\n",
    "```python\n",
    ">>> for name, shares, price in rows:\n",
    "        print(name, shares, price)\n",
    "\n",
    "AA 100 32.20\n",
    "IBM 50 91.10\n",
    "CAT 150 83.44\n",
    "MSFT 200 51.23\n",
    "GE 95 40.37\n",
    "MSFT 50 65.10\n",
    "IBM 100 70.44\n",
    ">>>\n",
    "```\n",
    "\n",
    "It's somewhat common to use `_` or `__` as a throw-away variable if you don't care\n",
    "about one or more of the values.  For example:\n",
    "\n",
    "```python\n",
    ">>> for name, _, price in rows:\n",
    "        print(name, price)\n",
    "\n",
    "AA 32.20\n",
    "IBM 91.10\n",
    "CAT 83.44\n",
    "MSFT 51.23\n",
    "GE 40.37\n",
    "MSFT 65.10\n",
    "IBM 70.44\n",
    ">>>\n",
    "```\n",
    "\n",
    "If you don't know how many values are being unpacked, you can use `*` as a wildcard.\n",
    "Try this experiment in grouping the data by name:\n",
    "\n",
    "```python\n",
    ">>> from collections import defaultdict\n",
    ">>> byname = defaultdict(list)\n",
    ">>> for name, *data in rows:\n",
    "        byname[name].append(data)\n",
    "\n",
    ">>> byname['IBM']\n",
    "[['50', '91.10'], ['100', '70.44']]\n",
    ">>> byname['CAT']\n",
    "[['150', '83.44']]\n",
    ">>> for shares, price in byname['IBM']:\n",
    "        print(shares, price)\n",
    "\n",
    "50 91.10\n",
    "100 70.44\n",
    ">>>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Counting with enumerate()\n",
    "\n",
    "`enumerate()` is a useful function if you ever need to keep a counter\n",
    "or index while iterating. For example, suppose you wanted an extra row\n",
    "number:\n",
    "\n",
    "```python\n",
    ">>> for rowno, row in enumerate(rows):\n",
    "        print(rowno, row)\n",
    "\n",
    "0 ['AA', '100', '32.20']\n",
    "1 ['IBM', '50', '91.10']\n",
    "2 ['CAT', '150', '83.44']\n",
    "3 ['MSFT', '200', '51.23']\n",
    "4 ['GE', '95', '40.37']\n",
    "5 ['MSFT', '50', '65.10']\n",
    "6 ['IBM', '100', '70.44']\n",
    ">>>\n",
    "```\n",
    "\n",
    "You can combine this with unpacking if you're careful about how you structure it:\n",
    "\n",
    "```python\n",
    ">>> for rowno, (name, shares, price) in enumerate(rows):\n",
    "        print(rowno, name, shares, price)\n",
    "\n",
    "0 AA 100 32.20\n",
    "1 IBM 50 91.10\n",
    "2 CAT 150 83.44\n",
    "3 MSFT 200 51.23\n",
    "4 GE 95 40.37\n",
    "5 MSFT 50 65.10\n",
    "6 IBM 100 70.44\n",
    ">>> \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Using the zip() function\n",
    "\n",
    "The `zip()` function is most commonly used to pair data.  For example,\n",
    "recall that you created a `headers` variable:\n",
    "\n",
    "```python\n",
    ">>> headers\n",
    "['name', 'shares', 'price']\n",
    ">>>\n",
    "```\n",
    "\n",
    "This might be useful to combine with the other row data:\n",
    "\n",
    "```python\n",
    ">>> row = rows[0]\n",
    ">>> row\n",
    "['AA', '100', '32.20']\n",
    ">>> for col, val in zip(headers, row):\n",
    "        print(col, val)\n",
    "\n",
    "name AA\n",
    "shares 100\n",
    "price 32.20\n",
    ">>>\n",
    "```\n",
    "\n",
    "Or maybe you can use it to make a dictionary:\n",
    "\n",
    "```python\n",
    ">>> dict(zip(headers, row))\n",
    "{'name': 'AA', 'shares': '100', 'price': '32.20'}\n",
    ">>>\n",
    "```\n",
    "\n",
    "Or maybe a sequence of dictionaries:\n",
    "\n",
    "```python\n",
    ">>> for row in rows:\n",
    "        record = dict(zip(headers, row))\n",
    "        print(record)\n",
    "\n",
    "{'name': 'AA', 'shares': '100', 'price': '32.20'}\n",
    "{'name': 'IBM', 'shares': '50', 'price': '91.10'}\n",
    "{'name': 'CAT', 'shares': '150', 'price': '83.44'}\n",
    "{'name': 'MSFT', 'shares': '200', 'price': '51.23'}\n",
    "{'name': 'GE', 'shares': '95', 'price': '40.37'}\n",
    "{'name': 'MSFT', 'shares': '50', 'price': '65.10'}\n",
    "{'name': 'IBM', 'shares': '100', 'price': '70.44'}\n",
    ">>>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Generator Expressions\n",
    "\n",
    "A generator expression is almost exactly the same as a list\n",
    "comprehension except that it does not create a list.  Instead, it\n",
    "creates an object that produces the results incrementally--typically\n",
    "for consumption by iteration. Try a simple example:\n",
    "\n",
    "```python\n",
    ">>> nums = [1,2,3,4,5]\n",
    ">>> squares = (x*x for x in nums)\n",
    ">>> squares\n",
    "<generator object <genexpr> at 0x37caa8>\n",
    ">>> for n in squares:\n",
    "        print(n)\n",
    "\n",
    "1\n",
    "4\n",
    "9\n",
    "16\n",
    "25\n",
    ">>>\n",
    "```\n",
    "\n",
    "You will notice that a generator expression can only be used once.\n",
    "Watch what happens if you do the for-loop again:\n",
    "\n",
    "```python\n",
    ">>> for n in squares:\n",
    "        print(n)\n",
    "\n",
    ">>>\n",
    "```\n",
    "\n",
    "You can manually get the results one-at-a-time if you use the\n",
    "`next()` function. Try this:\n",
    "\n",
    "```python\n",
    ">>> squares = (x*x for x in nums)\n",
    ">>> next(squares)\n",
    "1\n",
    ">>> next(squares)\n",
    "4\n",
    ">>> next(squares)\n",
    "9\n",
    ">>>\n",
    "```\n",
    "\n",
    "Keeping typing `next()` to see what happens when there is no\n",
    "more data.\n",
    "\n",
    "If the task you are performing is more complicated, you can\n",
    "still take advantage of generators by writing a generator function \n",
    "and using the `yield` statement instead.\n",
    "For example:\n",
    "\n",
    "```python\n",
    ">>> def squares(nums):\n",
    "        for x in nums:\n",
    "            yield x*x\n",
    "\n",
    ">>> for n in squares(nums):\n",
    "        print(n)\n",
    "\n",
    "1\n",
    "4\n",
    "9\n",
    "16\n",
    "25\n",
    ">>>\n",
    "```\n",
    "\n",
    "We'll return to generator functions a little later in the course--for now,\n",
    "just view such functions as having the interesting property of feeding\n",
    "values to the `for`-statement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) Generator Expressions and Reduction Functions\n",
    "\n",
    "Generator expressions are especially useful for feeding data into\n",
    "functions such as `sum()`, `min()`, `max()`,\n",
    "`any()`, etc.   Try some examples using the portfolio data from\n",
    "earlier.  Carefully observe that these examples are missing some\n",
    "extra square brackets ([]) that appeared when using list comprehensions.\n",
    "\n",
    "```python\n",
    ">>> from readport import read_portfolio\n",
    ">>> portfolio = read_portfolio('Data/portfolio.csv')\n",
    ">>> sum(s['shares']*s['price'] for s in portfolio)\n",
    "44671.15\n",
    ">>> min(s['shares'] for s in portfolio)\n",
    "50\n",
    ">>> any(s['name'] == 'IBM' for s in portfolio)\n",
    "True\n",
    ">>> all(s['name'] == 'IBM' for s in portfolio)\n",
    "False\n",
    ">>> sum(s['shares'] for s in portfolio if s['name'] == 'IBM')\n",
    "150\n",
    ">>>\n",
    "```\n",
    "\n",
    "Here is a subtle use of a generator expression in making comma\n",
    "separated values:\n",
    "\n",
    "```python\n",
    ">>> s = ('GOOG',100,490.10)\n",
    ">>> ','.join(s)\n",
    "... observe that it fails ...\n",
    ">>> ','.join(str(x) for x in s)    # This works\n",
    "'GOOG,100,490.1'\n",
    ">>>\n",
    "```\n",
    "\n",
    "The syntax in the above examples takes some getting used to, but the\n",
    "critical point is that none of the operations ever create a fully\n",
    "populated list of results.  This gives you a big memory savings.  However,\n",
    "you do need to make sure you don't go overboard with the syntax.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f) Saving a lot of memory\n",
    "\n",
    "In [Exercise 2.1](ex2_1.md) you wrote a function\n",
    "`read_rides_as_dicts()` that read the CTA bus data into a list of\n",
    "dictionaries.  Using it requires a lot of memory. For example,\n",
    "let's find the day on which the route 22 bus had the greatest\n",
    "ridership:\n",
    "\n",
    "```python\n",
    ">>> import tracemalloc\n",
    ">>> tracemalloc.start()\n",
    ">>> import readrides\n",
    ">>> rows = readrides.read_rides_as_dicts('Data/ctabus.csv')\n",
    ">>> rt22 = [row for row in rows if row['route'] == '22']\n",
    ">>> max(rt22, key=lambda row: row['rides'])\n",
    "{'date': '06/11/2008', 'route': '22', 'daytype': 'W', 'rides': 26896}\n",
    ">>> tracemalloc.get_traced_memory()\n",
    "... look at result. Should be around 220MB\n",
    ">>>\n",
    "```\n",
    "\n",
    "Now, let's try an example involving generators. Restart Python\n",
    "and try this:\n",
    "\n",
    "```python\n",
    ">>> # RESTART\n",
    ">>> import tracemalloc\n",
    ">>> tracemalloc.start()\n",
    ">>> import csv\n",
    ">>> f = open('Data/ctabus.csv')\n",
    ">>> f_csv = csv.reader(f)\n",
    ">>> headers = next(f_csv)\n",
    ">>> rows = (dict(zip(headers,row)) for row in f_csv)\n",
    ">>> rt22 = (row for row in rows if row['route'] == '22')\n",
    ">>> max(rt22, key=lambda row: int(row['rides']))\n",
    "{'date': '06/11/2008', 'route': '22', 'daytype': 'W', 'rides': 26896}\n",
    ">>> tracemalloc.get_traced_memory()\n",
    "... look at result. Should be a LOT smaller than before\n",
    ">>>\n",
    "```\n",
    "\n",
    "Keep in mind that you just processed the entire dataset as if it was\n",
    "stored as a sequence of dictionaries.  Yet, nowhere did you actually\n",
    "create and store a list of dictionaries.   Not all problems can be\n",
    "structured in this way, but if you can work with data in an\n",
    "iterative manner, generator expressions can save a huge amount of memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By Dict\n",
      "{'route': '22', 'date': '06/11/2008', 'daytype': 'W', 'rides': 26896}\n",
      "Current :  22.520078 MBs Maxi :  22.522845125 MBs\n",
      "By Generators\n",
      "{'route': '22', 'date': '06/11/2008', 'daytype': 'W', 'rides': '26896'}\n",
      "Current :  0.091246625 MBs Maxi :  22.5241865 MBs\n"
     ]
    }
   ],
   "source": [
    "import tracemalloc\n",
    "\n",
    "def convert_to_mb(bits):\n",
    "    return bits / (8 * 1_000_000)\n",
    "\n",
    "print(\"By Dict\")\n",
    "tracemalloc.start()\n",
    "rows = read_rides_as_dicts(\"E:/jai/docs/code/python/tutorial/learning-python-mastery/Data/ctabus.csv\")\n",
    "rt22 = [row for row in rows if row['route'] == '22'] # list comprehension\n",
    "print(max(rt22, key=lambda row: row['rides']))\n",
    "curr,maxi = tracemalloc.get_traced_memory()\n",
    "print(\"Current : \",convert_to_mb(curr),\"MBs\",\"Maxi : \",convert_to_mb(maxi),\"MBs\")\n",
    "\n",
    "print(\"By Generators\")\n",
    "\n",
    "tracemalloc.start()\n",
    "import csv\n",
    "with open(\"E:/jai/docs/code/python/tutorial/learning-python-mastery/Data/ctabus.csv\") as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    header = next(f_csv)\n",
    "    rows = (dict(zip(header,row)) for row in f_csv) # generator\n",
    "    rt22 = (row for row in rows if row['route'] == '22') # generator\n",
    "    print(max(rt22,key=lambda row: int(row['rides'])))\n",
    "    curr,maxi = tracemalloc.get_traced_memory()\n",
    "    print(\"Current : \",convert_to_mb(curr),\"MBs\",\"Maxi : \",convert_to_mb(maxi),\"MBs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the builtins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
